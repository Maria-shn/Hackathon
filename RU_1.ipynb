{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nrclex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYmpGQD0mkf4",
        "outputId": "c289bb27-926c-4dcb-e316-cb66d6116fc1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nrclex in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (from nrclex) (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob->nrclex) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from nltk.metrics import edit_distance\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from nrclex import NRCLex\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1avNd_JPmolm",
        "outputId": "d32a1aeb-4cfd-496d-baea-b9a59f955b06"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_emotions(text):\n",
        "    emotion = NRCLex(text)\n",
        "    return emotion.affect_frequencies\n",
        "\n",
        "\n",
        "# Example usage\n",
        "text = \"Hi, I'm having a problem with my computer. The screen is completely blank and I can't see anything. Can you help me?\"\n",
        "emotion = analyze_emotions(text)\n",
        "\n",
        "# Print the emotion and its score\n",
        "for e, score in emotion.items():\n",
        "    print(f\"{e}: {score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C0HfxFjm7kt",
        "outputId": "5643a8cb-105a-4d15-9ca5-279d62188451"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fear: 0.25\n",
            "anger: 0.0\n",
            "anticip: 0.0\n",
            "trust: 0.0\n",
            "surprise: 0.0\n",
            "positive: 0.25\n",
            "negative: 0.25\n",
            "sadness: 0.25\n",
            "disgust: 0.0\n",
            "joy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_emotion_finish_score(emotion_scores):\n",
        "    neg = 0\n",
        "    pos = 0\n",
        "    for emotion in emotion_scores:\n",
        "\n",
        "        if (emotion == \"anger\" or emotion == \"disgust\" or emotion == \"negative\"):\n",
        "            neg += emotion_scores[emotion]\n",
        "        elif (emotion == \"joy\" or emotion == \"positive\" or \"trust\"):\n",
        "            pos += emotion_scores[emotion]\n",
        "\n",
        "    if (pos == 0):\n",
        "        if (neg != 0):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    else:\n",
        "        return (neg/pos)"
      ],
      "metadata": {
        "id": "Me8nscUgcKD2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "\n",
        "    client_answers = []\n",
        "\n",
        "    agent_answers = []\n",
        "    current_role = None\n",
        "\n",
        "    with open('conversation_sample3.txt', 'r') as file:\n",
        "        for line in file:\n",
        "            role, answer = line.strip().split(\": \", 1)\n",
        "\n",
        "            if role == \"Client\":\n",
        "                if current_role != \"Client\":\n",
        "                    client_answers.append(answer)\n",
        "                else:\n",
        "                    client_answers[-1] += \" \" + answer\n",
        "                current_role = \"Client\"\n",
        "\n",
        "            elif role == \"Agent\":\n",
        "                if current_role != \"Agent\":\n",
        "                    agent_answers.append(answer)\n",
        "                else:\n",
        "                    agent_answers[-1] += \" \" + answer\n",
        "                current_role = \"Agent\"\n",
        "\n",
        "\n",
        "# Print the client and agent answers\n",
        "    for i in range(len(client_answers)):\n",
        "        print(\"Iteration\", i+1)\n",
        "        print(\"Client answer:\", client_answers[i])\n",
        "        if i < len(agent_answers):\n",
        "            print(\"Agent answer:\", agent_answers[i])\n",
        "        print()\n",
        "\n",
        "# Print the client and agent answers for each iteration\n",
        "    for i in range(len(client_answers)):\n",
        "        print(\"Iteration\", i+1)\n",
        "        print(\"Client answer:\", client_answers[i])\n",
        "        if i < len(agent_answers):\n",
        "            print(\"Agent answer:\", agent_answers[i])\n",
        "        print()\n",
        "\n",
        "    client_emotions = {}\n",
        "\n",
        "    for i in range(len(client_answers)):\n",
        "        client_emotions[client_answers[i]\n",
        "                        ] = analyze_emotions(client_answers[i])\n",
        "        print(\"client emotions: \", client_emotions[client_answers[i]])\n",
        "\n",
        "    client_emotions_finished_scores = {}\n",
        "\n",
        "    for i in range(len(client_answers)):\n",
        "        client_emotions_finished_scores[client_answers[i]] = calculate_emotion_finish_score(\n",
        "            client_emotions[client_answers[i]])\n",
        "        print(\"client emotions finished scores: \",\n",
        "              client_emotions_finished_scores[client_answers[i]])\n",
        "    bad_ans=[]\n",
        "    threshold = 0.5\n",
        "    for i in range(len(client_emotions_finished_scores)):\n",
        "        if (client_emotions_finished_scores[client_answers[i]] >= threshold): \n",
        "            bad_ans.append(agent_answers[i-1])\n",

        "\n",
        "    finished_avg = 0\n",
        "    for i in range(len(client_answers)):\n",
        "        if (i != 0 ):\n",
        "          if (calculate_emotion_finish_score(client_emotions[client_answers[i]]) >= 0.5):\n",
        "            finished_avg += 1\n",
        "          else:\n",
        "            finished_avg-=1\n",
        "\n",
        "    if (finished_avg > 0):\n",
        "      api_using(agent_answers)"
      ],
      "metadata": {
        "id": "KkMM6Xt7m-uq"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zdLsUtWnBjx",
        "outputId": "0879e7e6-b94e-41c0-a23b-f937a8111de9"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1\n",
            "Client answer: Hi, I'm calling because my package still hasn't arrived.\n",
            "Agent answer: What do you expect me to do about it? I can't control the delivery process.\n",
            "\n",
            "Iteration 2\n",
            "Client answer: Well, I understand that, but I'm just looking for some assistance or information regarding my package.\n",
            "Agent answer: Did you even bother to track your package? It's not my problem if you can't keep track of your own deliveries.\n",
            "\n",
            "Iteration 3\n",
            "Client answer: Yes, I tracked it, but it shows that it was delivered, and I never received it.\n",
            "Agent answer: Are you sure you didn't just misplace it? Maybe you should look around your house before blaming us.\n",
            "\n",
            "Iteration 4\n",
            "Client answer: I've already checked everywhere, and I'm certain it's not here. I just want some help in resolving this issue.\n",
            "Agent answer: Look, I don't have time for this. If you're not satisfied, you can file a complaint, but I can't guarantee anything will be done about it.\n",
            "\n",
            "Iteration 5\n",
            "Client answer: This is unacceptable. I expect better customer service. Can I speak to your supervisor?\n",
            "Agent answer: No, I'm the only one here, and I've already wasted enough time on this call. Is there anything else I can help you with?\n",
            "\n",
            "Iteration 6\n",
            "Client answer: No, thank you. I'll find another way to address this issue.\n",
            "\n",
            "Iteration 1\n",
            "Client answer: Hi, I'm calling because my package still hasn't arrived.\n",
            "Agent answer: What do you expect me to do about it? I can't control the delivery process.\n",
            "\n",
            "Iteration 2\n",
            "Client answer: Well, I understand that, but I'm just looking for some assistance or information regarding my package.\n",
            "Agent answer: Did you even bother to track your package? It's not my problem if you can't keep track of your own deliveries.\n",
            "\n",
            "Iteration 3\n",
            "Client answer: Yes, I tracked it, but it shows that it was delivered, and I never received it.\n",
            "Agent answer: Are you sure you didn't just misplace it? Maybe you should look around your house before blaming us.\n",
            "\n",
            "Iteration 4\n",
            "Client answer: I've already checked everywhere, and I'm certain it's not here. I just want some help in resolving this issue.\n",
            "Agent answer: Look, I don't have time for this. If you're not satisfied, you can file a complaint, but I can't guarantee anything will be done about it.\n",
            "\n",
            "Iteration 5\n",
            "Client answer: This is unacceptable. I expect better customer service. Can I speak to your supervisor?\n",
            "Agent answer: No, I'm the only one here, and I've already wasted enough time on this call. Is there anything else I can help you with?\n",
            "\n",
            "Iteration 6\n",
            "Client answer: No, thank you. I'll find another way to address this issue.\n",
            "\n",
            "client emotions:  {'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 'trust': 0.0, 'surprise': 0.0, 'positive': 0.0, 'negative': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
            "client emotions:  {'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 'trust': 0.0, 'surprise': 0.0, 'positive': 1.0, 'negative': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
            "client emotions:  {'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 'trust': 0.0, 'surprise': 0.0, 'positive': 1.0, 'negative': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
            "client emotions:  {'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 'trust': 0.0, 'surprise': 0.0, 'positive': 0.0, 'negative': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
            "client emotions:  {'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 'trust': 0.14285714285714285, 'surprise': 0.14285714285714285, 'positive': 0.2857142857142857, 'negative': 0.14285714285714285, 'sadness': 0.14285714285714285, 'disgust': 0.0, 'joy': 0.0, 'anticipation': 0.14285714285714285}\n",
            "client emotions:  {'fear': 0.0, 'anger': 0.0, 'anticip': 0.0, 'trust': 0.0, 'surprise': 0.0, 'positive': 0.0, 'negative': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
            "client emotions finished scores:  0\n",
            "client emotions finished scores:  0.0\n",
            "client emotions finished scores:  0.0\n",
            "client emotions finished scores:  0\n",
            "client emotions finished scores:  0.16666666666666669\n",
            "client emotions finished scores:  0\n",
            "The customer support agent should be more empathetic and understanding\n",
            "Instead of asking \"What do you expect me to do about it?\", the agent could say something like \"I understand how frustrating this must be for you\n",
            "Let's see how we can resolve this issue together\"\n",
            "Additionally, the agent should avoid being confrontational and instead try to remain professional and courteous\n",
            "For example, instead of saying \"Did you even bother to track your package? It's not my problem if you can't keep track of your own deliveries.\", the agent could say \"Can you tell me more about the delivery process so I can help you better?\"\n",
            "Lastly, the agent should offer solutions and not just dismiss the customer's concerns\n",
            "For example, instead of saying \"Look, I don't have time for this\n",
            "If you're not satisfied, you can file a complaint, but I can't guarantee anything will be done about it.\", the agent could say \"I apologize for the inconvenience\n",
            "I'm happy to help you file a complaint, and I will do my best to ensure a satisfactory resolution for you\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsVjrKZ1qK7u",
        "outputId": "3e23b991-df53-49a9-e1fd-f620d0b8826a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "Tn-yMp3YrN4L"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def api_using(bad_ans):\n",
        "  prompt = \"These are the answers from customer support in conversation with a client. The client left angry. Suggest how the customer support agent could improve, give examples:\\n\\n\"\n",
        "  for i in range(len(bad_ans)):\n",
        "    prompt += bad_ans[i]\n",
        "    prompt +=\"\\n\"\n",
        "\n",
        "  model = \"text-davinci-003\"\n",
        "  completions = openai.Completion.create(engine=model, prompt=prompt, max_tokens=2048, n=1, stop=None, temperature=0.5)\n",
        "  completions.choices[0].text\n",
        "  generated_text = completions.choices[0].text\n",
        "  sentence_list = generated_text.split('. ')\n",
        "  for sentence in sentence_list:\n",
        "    print(sentence.strip())\n"
      ],
      "metadata": {
        "id": "09jqcXqqrWoK"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dictionary to a string\n",
        "emotion_string = ' '.join([f\"{k}:{v:.2f}\" for k,v in emotion.items()])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_vYh4k5GtSSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jwRRg6Vsu3lp",
        "outputId": "899d18c0-aec0-492d-e880-8a1fbd3e9c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fear:0.25 anger:0.00 anticip:0.00 trust:0.00 surprise:0.00 positive:0.25 negative:0.25 sadness:0.25 disgust:0.00 joy:0.00'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# emotion_string = 'fear:0.10 anger:0.20 anticip:0.05 trust:0.50 surprise:0.10 positive:0.05 negative:0.70 sadness:0.60 disgust:0.05 joy:0.05 anticipation:0.05'\n",
        "\n",
        "prompt = f\"I have analyzed the emotions of our agents and found that the overall sentiment is {emotion['positive']:.2f} positive, {emotion['negative']:.2f} negative, {emotion['sadness']:.2f} sadness, {emotion['anger']:.2f} angry, and {emotion['disgust']:.2f} sad. Based on this analysis, we may need to provide additional support to agents who are feeling particularly sad or angry. Would you like me to provide some suggestions for how we can address these emotions?\"\n",
        "\n",
        "print(prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiL8YCyDuzFU",
        "outputId": "2d013f7c-5e26-4914-96b8-02415c90612e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have analyzed the emotions of our agents and found that the overall sentiment is 0.25 positive, 0.25 negative, 0.25 sadness, 0.00 angry, and 0.00 sad. Based on this analysis, we may need to provide additional support to agents who are feeling particularly sad or angry. Would you like me to provide some suggestions for how we can address these emotions?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QZRzH6ULrYbb",
        "outputId": "261fd6cd-820a-4e31-8c29-dcae6fcba76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I do not sense anyone feeling particularly sad at the moment. Is there anything else I can help you with?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"text-davinci-002\"\n",
        "completions = openai.Completion.create(engine=model, prompt=prompt, max_tokens=1024, n=1, stop=None, temperature=0.5)"
      ],
      "metadata": {
        "id": "3sIcF99yqIRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completions.choices[0].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bNQwlJSpuSiM",
        "outputId": "96f6f35f-b16f-4640-87f8-ff8b2f659184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text = completions.choices[0].text\n",
        "sentence_list = generated_text.split('. ')\n",
        "for sentence in sentence_list:\n",
        "  print(sentence.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EADVvXVor4Jw",
        "outputId": "7e83cd11-e2a4-4254-bd33-5b651a8210af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, I would appreciate some suggestions for how to address the emotions of our agents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH2dNe8rme2a"
      },
      "outputs": [],
      "source": [
        "# Load data dictionary (assuming it's a dictionary with sentence as key and emotion score as value)\n",
        "data_dict = {\n",
        "    \"I am happy.\": 0.8,\n",
        "    \"I am sad.\": 0.2,\n",
        "    \"you are useless\": 0.1,\n",
        "    \"you are great\": 0.9,\n",
        "    \"I am angry\": 0.1,\n",
        "    \"I hate you\": 0.1,\n",
        "    \"I love you\": 0.9,\n",
        "    \"I am so happy\": 0.9,\n",
        "    \"I am so sad\": 0.1,\n",
        "    \"I am so angry\": 0.1,\n",
        "    \"I am so useless\": 0.1,\n",
        "\n",
        "}\n",
        "\n",
        "# Preprocess sentences (example using NLTK for tokenization and stopword removal)\n",
        "\n",
        "# Load data dictionary (assuming it's a dictionary with sentence as key and emotion score as value)\n",
        "data_dict = {\n",
        "    \"I am happy.\": 0.8,\n",
        "    \"I am sad.\": 0.2,\n",
        "    # more sentences...\n",
        "}\n",
        "\n",
        "\n",
        "# Sample data\n",
        "\n",
        "# Sample data\n",
        "\n",
        "# Sample data\n",
        "\n",
        "# Sample data\n",
        "\n",
        "# Sample data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"I am feeling happy\",\n",
        "    \"I feel sad\",\n",
        "    \"Feeling joyful\",\n",
        "    \"I am not happy\",\n",
        "    \"I am ecstatic\"\n",
        "]\n",
        "\n",
        "# Sample emotion scores\n",
        "emotion_scores = [0.8, 0.5, 0.9, 0.3, 0.7]\n",
        "\n",
        "# Load spaCy's English language model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Calculate similarity scores\n",
        "similarity_scores = []\n",
        "for i, sentence in enumerate(sentences):\n",
        "    doc1 = nlp(sentence)\n",
        "    scores = []\n",
        "    for j, other_sentence in enumerate(sentences):\n",
        "        if i != j:  # Exclude self-comparison\n",
        "            doc2 = nlp(other_sentence)\n",
        "            scores.append(doc1.similarity(doc2))\n",
        "    similarity_scores.append(scores)\n",
        "\n",
        "# Sort sentences based on similarity scores and emotion scores\n",
        "sorted_sentences = sorted(zip(\n",
        "    sentences, similarity_scores, emotion_scores), key=lambda x: (-max(x[1]), x[2]))\n",
        "\n",
        "# Print top 5 sentences with highest similarity scores and low emotion scores\n",
        "for i in range(5):\n",
        "    print(\"Sentence:\", sorted_sentences[i][0])\n",
        "    print(\"Similarity Score:\", max(sorted_sentences[i][1]))\n",
        "    print(\"Emotion Score:\", sorted_sentences[i][2])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "Fq4MQEm7nFvM",
        "outputId": "fddc0fe9-dc1f-45ce-a6f2-25f8dbbc5c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b1c920b1d969>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load spaCy's English language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_md\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Calculate similarity scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ]
    }
  ]
}
